{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from os.path import join\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping, History, TensorBoard, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_base_dir = \"./logs\"\n",
    "os.makedirs(logs_base_dir, exist_ok=True)\n",
    "%tensorboard --logdir {logs_base_dir}\n",
    "\n",
    "%tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_weights_name = \"save_weights\"\n",
    "checkpoint_path = join(folder_weights_name, 'weights')\n",
    "\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1108 19:00:50.987185 4638746048 base.py:272] Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0xb33710c18> and <tensorflow.python.keras.layers.core.Dropout object at 0xb33710b00>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_weights/weights\n"
     ]
    }
   ],
   "source": [
    "# To load the weights and evaluate the performace from a previous model\n",
    "# we need to generate a new model instance\n",
    "model = model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "      tf.keras.layers.Dense(128, activation='relu'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "print(latest)\n",
    "\n",
    "# Load the previously saved weights\n",
    "model.load_weights(latest)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 1s - loss: 1.1444 - accuracy: 0.5402\n",
      "Restored model, accuracy: 54.02%\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "loss, acc = model.evaluate(x_test,  y_test, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = os.path.dirname(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [43941 16565  3582 16743 21846 13094 36857 51583 47753  1103]\n",
    "# [[ 6394, 10985, 26146, 24512, 47211, 54289, 34046, 13024, 48617, 8563]\n",
    "# [27894, 41222, 37632,  2735, 42382,  9800, 32978,  5897, 32480, 45969]\n",
    "\n",
    "# 51737, 10259, 43404\n",
    "#15253,  3925, 50169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[50169])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(X, edge):\n",
    "    \"\"\"Here we pass the data matrix, the tensor of dimensions (#n_samples, dim1, dim2) \"\"\"\n",
    "    _, dim1, dim2 = X.shape\n",
    "    X_ = X[:, edge:dim1-edge, edge:dim2-edge]\n",
    "    return X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e_ in [2, 4, 6, 8, 9, 10]:\n",
    "    xx = crop(x_train, e_)\n",
    "    plt.imshow(xx[3])\n",
    "    plt.show()\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_, dim1, dim2 = xx.shape\n",
    "xx = np.reshape(xx, (n_, -1), order='C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(X, edge=3):\n",
    "    \"\"\" Here we pass the data matrix, the tensor of dimensions (#n_samples, dim1, dim2) \"\"\"\n",
    "    _, dim1, dim2 = X.shape\n",
    "    X_ = X[:, edge:dim1-edge, edge:dim2-edge]\n",
    "    return X_\n",
    "\n",
    "\n",
    "def pyramid(X, edge_list=[0, 2, 4, 6, 8, 9, 10]):\n",
    "    \"\"\" Here we make the pyramid, meaning that we zoom into the data \"\"\"\n",
    "    n_samples, dim1, dim2 = X.shape\n",
    "    for i_, e_ in enumerate(edge_list):\n",
    "        if i_ == 0:\n",
    "            X_ = np.reshape(crop(X, e_), (n_samples, -1), order='C')\n",
    "        else:\n",
    "            X_ = np.hstack((X_, np.reshape(crop(X, e_), (n_samples,-1), order='C')))\n",
    "    return np.reshape(X_, (n_samples, X_.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = pyramid(x_train, edge_list=[4,8,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0][4:24, 4:24].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[0][4:24, 4:24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(xxx[0, 20**2:20**2+12**2].reshape(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = np.arange(5, 50, 5)\n",
    "edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_training = np.load('example_results/n_training_array.npy')\n",
    "test_acc = np.load('example_results/original/test_acc.npy')\n",
    "test_loss = np.load('example_results/original/test_loss.npy')\n",
    "\n",
    "mean_acc = test_acc.mean(axis=0)\n",
    "std_acc = test_acc.std(axis=0)\n",
    "plt.fill_between(n_training, mean_acc-std_acc, mean_acc+std_acc, alpha=0.2)\n",
    "plt.plot(n_training, mean_acc, 'o-', linewidth=3)\n",
    "plt.xticks(fontsize='xx-large')\n",
    "plt.yticks(fontsize='xx-large')\n",
    "plt.ylabel('test accuracy', fontsize='xx-large')\n",
    "plt.xlabel('#training samples', fontsize='xx-large')\n",
    "plt.grid()\n",
    "plt.xlim([n_training[0]-0.1,n_training[-1]+0.1]);\n",
    "plt.show();\n",
    "\n",
    "mean_loss = test_loss.mean(axis=0)\n",
    "std_loss = test_loss.std(axis=0)\n",
    "n_training = np.load('example_results/n_training_array.npy')\n",
    "plt.fill_between(n_training, mean_loss-std_loss, mean_loss+std_loss, alpha=0.2)\n",
    "plt.plot(n_training, mean_loss, 'o-', linewidth=3)\n",
    "plt.xticks(fontsize='xx-large')\n",
    "plt.yticks(fontsize='xx-large')\n",
    "plt.ylabel('test loss', fontsize='xx-large')\n",
    "plt.xlabel('#training samples', fontsize='xx-large')\n",
    "plt.grid()\n",
    "plt.xlim([n_training[0]-0.1,n_training[-1]+0.1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_training = np.load('example_results/n_training_array.npy')\n",
    "test_acc_crop = np.load('example_results/crop/test_acc.npy')\n",
    "test_loss_crop = np.load('example_results/crop/test_loss.npy')\n",
    "mean_acc_crop = test_acc_crop.mean(axis=0)\n",
    "std_acc_crop = test_acc_crop.std(axis=0)\n",
    "\n",
    "test_acc = np.load('example_results/original/test_acc.npy')\n",
    "test_loss = np.load('example_results/original/test_loss.npy')\n",
    "mean_acc = test_acc.mean(axis=0)\n",
    "std_acc = test_acc.std(axis=0)\n",
    "\n",
    "plt.fill_between(n_training, mean_acc-std_acc, mean_acc+std_acc, alpha=0.2, color='C0')\n",
    "plt.plot(n_training, mean_acc, 'o-', linewidth=3, color='C0', label='original')\n",
    "\n",
    "plt.fill_between(n_training, mean_acc_crop-std_acc_crop, \n",
    "                 mean_acc_crop+std_acc_crop, alpha=0.2, color='C1')\n",
    "plt.plot(n_training, mean_acc_crop, 'o-', linewidth=3, color='C1', label='cropped')\n",
    "plt.xticks(fontsize='xx-large')\n",
    "plt.yticks(fontsize='xx-large')\n",
    "plt.ylabel('test accuracy', fontsize='xx-large')\n",
    "plt.xlabel('#training samples', fontsize='xx-large')\n",
    "plt.grid()\n",
    "plt.xlim([n_training[0]-0.1,n_training[-1]+0.1]);\n",
    "plt.legend(fontsize='xx-large')\n",
    "plt.show();\n",
    "\n",
    "mean_loss = test_loss.mean(axis=0)\n",
    "std_loss = test_loss.std(axis=0)\n",
    "n_training = np.load('example_results/n_training_array.npy')\n",
    "plt.fill_between(n_training, mean_loss-std_loss, mean_loss+std_loss, alpha=0.2, color='C0')\n",
    "plt.plot(n_training, mean_loss, 'o-', linewidth=3, color='C0', label='original')\n",
    "plt.fill_between(n_training, mean_loss_crop-std_loss_crop, \n",
    "                 mean_loss_crop+std_loss_crop, alpha=0.2, color='C1')\n",
    "plt.plot(n_training, mean_loss_crop, 'o-', linewidth=3, color='C1', label='cropped')\n",
    "plt.xticks(fontsize='xx-large')\n",
    "plt.yticks(fontsize='xx-large')\n",
    "plt.ylabel('test loss', fontsize='xx-large')\n",
    "plt.xlabel('#training samples', fontsize='xx-large')\n",
    "plt.grid()\n",
    "plt.xlim([n_training[0]-0.1,n_training[-1]+0.1]);\n",
    "plt.legend(fontsize='xx-large')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_training = np.load('example_results/n_training_array.npy')\n",
    "test_acc_pyr = np.load('example_results/pyramid_all_layers/test_acc.npy')\n",
    "test_loss_pyr = np.load('example_results/pyramid_all_layers/test_loss.npy')\n",
    "mean_acc_pyr = test_acc_pyr.mean(axis=0)\n",
    "std_acc_pyr = test_acc_pyr.std(axis=0)\n",
    "\n",
    "plt.fill_between(n_training, mean_acc-std_acc, \n",
    "                 mean_acc+std_acc, alpha=0.2, color='C0')\n",
    "plt.plot(n_training, mean_acc, 'o-', linewidth=3, color='C0', label='original')\n",
    "plt.fill_between(n_training, mean_acc_pyr-std_acc_pyr, \n",
    "                 mean_acc_pyr+std_acc_pyr, alpha=0.2, color='C1')\n",
    "plt.plot(n_training, mean_acc_pyr, 'o-', linewidth=3, color='C1', label='inverted-pyr')\n",
    "\n",
    "plt.xticks(fontsize='xx-large')\n",
    "plt.yticks(fontsize='xx-large')\n",
    "plt.ylabel('test accuracy', fontsize='xx-large')\n",
    "plt.xlabel('#training samples', fontsize='xx-large')\n",
    "plt.grid()\n",
    "plt.xlim([n_training[0]-0.1,n_training[-1]+0.1]);\n",
    "plt.legend(fontsize='xx-large')\n",
    "plt.title('pyramid w all crops', fontsize='xx-large')\n",
    "plt.tight_layout()\n",
    "plt.savefig('pyramid_acc.pdf')\n",
    "plt.show();\n",
    "\n",
    "mean_loss_pyr = test_loss_pyr.mean(axis=0)\n",
    "std_loss_pyr = test_loss_pyr.std(axis=0)\n",
    "n_training = np.load('example_results/n_training_array.npy')\n",
    "plt.fill_between(n_training, mean_loss-std_loss, mean_loss+std_loss, alpha=0.2, color='C0')\n",
    "plt.plot(n_training, mean_loss, 'o-', linewidth=3, color='C0', label='original')\n",
    "plt.fill_between(n_training, mean_loss_pyr-std_loss_pyr, \n",
    "                 mean_loss_pyr+std_loss_pyr, alpha=0.2, color='C1')\n",
    "plt.plot(n_training, mean_loss_pyr, 'o-', linewidth=3, color='C1', label='inverted-pyr')\n",
    "plt.xticks(fontsize='xx-large')\n",
    "plt.yticks(fontsize='xx-large')\n",
    "plt.ylabel('test loss', fontsize='xx-large')\n",
    "plt.xlabel('#training samples', fontsize='xx-large')\n",
    "plt.grid()\n",
    "plt.xlim([n_training[0]-0.1,n_training[-1]+0.1]);\n",
    "plt.legend(fontsize='xx-large')\n",
    "plt.title('pyramid w all crops', fontsize='xx-large')\n",
    "plt.tight_layout()\n",
    "plt.savefig('pyramid_loss.pdf')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_pyr = np.load('example_results/pyramid_zoomed_in/test_acc.npy')\n",
    "test_loss_pyr = np.load('example_results/pyramid_zoomed_in/test_loss.npy')\n",
    "\n",
    "plt.fill_between(n_training, mean_acc-std_acc, \n",
    "                 mean_acc+std_acc, alpha=0.2, color='C0')\n",
    "plt.plot(n_training, mean_acc, 'o-', linewidth=3, color='C0', label='original')\n",
    "plt.fill_between(n_training, mean_acc_pyr-std_acc_pyr, \n",
    "                 mean_acc_pyr+std_acc_pyr, alpha=0.2, color='C1')\n",
    "plt.plot(n_training, mean_acc_pyr, 'o-', linewidth=3, color='C1', label='inverted-pyr')\n",
    "\n",
    "plt.xticks(fontsize='xx-large')\n",
    "plt.yticks(fontsize='xx-large')\n",
    "plt.ylabel('test accuracy', fontsize='xx-large')\n",
    "plt.xlabel('#training samples', fontsize='xx-large')\n",
    "plt.grid()\n",
    "plt.xlim([n_training[0]-0.1,n_training[-1]+0.1]);\n",
    "plt.legend(fontsize='xx-large')\n",
    "plt.title('pyramid w few crops', fontsize='xx-large')\n",
    "plt.tight_layout()\n",
    "plt.savefig('pyramid_acc.pdf')\n",
    "plt.show();\n",
    "\n",
    "\n",
    "mean_loss_pyr = test_loss_pyr.mean(axis=0)\n",
    "std_loss_pyr = test_loss_pyr.std(axis=0)\n",
    "n_training = np.load('example_results/n_training_array.npy')\n",
    "plt.fill_between(n_training, mean_loss-std_loss, mean_loss+std_loss, alpha=0.2, color='C0')\n",
    "plt.plot(n_training, mean_loss, 'o-', linewidth=3, color='C0', label='original')\n",
    "plt.fill_between(n_training, mean_loss_pyr-std_loss_pyr, \n",
    "                 mean_loss_pyr+std_loss_pyr, alpha=0.2, color='C1')\n",
    "plt.plot(n_training, mean_loss_pyr, 'o-', linewidth=3, color='C1', label='inverted-pyr')\n",
    "plt.xticks(fontsize='xx-large')\n",
    "plt.yticks(fontsize='xx-large')\n",
    "plt.ylabel('test loss', fontsize='xx-large')\n",
    "plt.xlabel('#training samples', fontsize='xx-large')\n",
    "plt.grid()\n",
    "plt.xlim([n_training[0]-0.1,n_training[-1]+0.1]);\n",
    "plt.legend(fontsize='xx-large')\n",
    "plt.title('pyramid w few crops', fontsize='xx-large')\n",
    "plt.tight_layout()\n",
    "plt.savefig('pyramid_loss_few_layers.pdf')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.append(0, np.cumsum(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?? np.reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = np.load(join('./red_square', 'x_test.npy'))\n",
    "print(datafile.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "24**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dim_val = 0\n",
    "ex = datafile[2]\n",
    "for e_ in [0, 2, 4, 6, 8, 9, 10]:\n",
    "    \n",
    "    xx = np.reshape(a=ex[dim_val:dim_val+(dim-(2*e_))**2], newshape=(dim-(2*e_),dim-(2*e_)), order='C')\n",
    "    dim_val += (dim-(2*e_))**2\n",
    "    print((dim-(2*e_))**2)\n",
    "    print(dim_val)\n",
    "    plt.imshow(xx, vmin=0, vmax=1)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(generate_bool_mask(x_test)[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(3.49).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 7, 14, 26, 61]\n",
      "4\n",
      "7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5c7c78a92b01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mx_up\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-5c7c78a92b01>\u001b[0m in \u001b[0;36mupscale\u001b[0;34m(x, e)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_diff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0me\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmin_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 tmp_array = np.array([x_[n, i-min_diff:i+min_diff+1, \n\u001b[0;32m---> 20\u001b[0;31m                                         j-min_diff:j+min_diff+1]])\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mtmp_non_zeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtmp_non_zeros\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def upscale(x, e=2):\n",
    "    n_samples, dim1, dim2 = x.shape\n",
    "    c = 0\n",
    "    ll = np.zeros(dim1, dtype=int)\n",
    "    \n",
    "    for k in range(dim1):\n",
    "        ll[k] = np.round(c).astype(int)\n",
    "        c += (dim1+2*e) / dim1\n",
    "    min_diff = np.min(np.diff(ll))\n",
    "\n",
    "    x_ = np.zeros((n_samples, dim1+2*e, dim2+2*e))\n",
    "    dimyy, dimxx = np.meshgrid(ll, ll)\n",
    "    x_[:, dimxx, dimyy] = x\n",
    "    \n",
    "    x__ = x_.copy()\n",
    "    for n in range(n_samples):\n",
    "        for i in range(min_diff, dim1+2*e - min_diff):\n",
    "            for j in range(min_diff, dim2+2*e - min_diff):\n",
    "                tmp_array = np.array([x_[n, i-min_diff:i+min_diff+1, \n",
    "                                        j-min_diff:j+min_diff+1]])\n",
    "                tmp_non_zeros = np.count_nonzero(tmp_array)\n",
    "                if tmp_non_zeros > 0:\n",
    "                    x__[n, i, j] = np.sum(tmp_array) / tmp_non_zeros  # normalize in some way\n",
    "                    \n",
    "    return x__\n",
    "\n",
    "# x_up = upscale(x_test)\n",
    "\n",
    "edges = [int((ii-28)/2) for ii in [36, 42, 56, 80, 150]]\n",
    "print(edges)\n",
    "for e_ in edges:\n",
    "    print(e_)\n",
    "    x_up = upscale(x_test, e_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale(x, e=4):\n",
    "    n_samples, dim1, dim2 = x.shape\n",
    "    c = 0\n",
    "    ll = np.zeros(dim1, dtype=int)\n",
    "    \n",
    "    for k in range(dim1):\n",
    "        ll[k] = np.round(c).astype(int)\n",
    "        c += (dim1+2*e) / dim1\n",
    "        \n",
    "    print(np.max(np.diff(ll)), ll)\n",
    "\n",
    "    x_ = np.zeros((n_samples, dim1+2*e, dim2+2*e))\n",
    "    dimyy, dimxx = np.meshgrid(ll, ll)\n",
    "    x_[:, dimxx, dimyy] = x\n",
    "    \n",
    "    x__ = x_.copy()\n",
    "    return x__\n",
    "\n",
    "plt.imshow(upscale(x_test[:3], e=10)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(10)[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
